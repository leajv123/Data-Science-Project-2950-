{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phase IV: Preregistration of Analyses\n",
    "\n",
    "#### by Katherine Vella (skv25), Fatima Yuen (fy46), and Lea Jih-Vieira (laj74)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table of Contents:\n",
    "I. Introduction </br>\n",
    "II. Data Description </br>\n",
    "III. Preregistration Statement </br>\n",
    "IV. Data Analyses </br>\n",
    "V. Evaluation of Significance </br>\n",
    "VI. Interpretations and Conclusions </br>\n",
    "VII. Source Code </br>\n",
    "VIII. Acknowledgements </br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## I. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The History of Stop-and-Frisk in NYC:\n",
    "\n",
    "The New York Police Department’s stop-and-frisk program is a crime-prevention strategy in which officers temporarily detain, question, and often search individuals suspected of carrying weapons or contraband. The program gained traction in the early 2000s under Mayor Michael Bloomberg and reached its height in 2011, a year in which an estimated 685,724 civilians were stopped by the NYPD. In August of 2013, US District Court Judge Sheila Scheindlin ruled in Floyd v. City of New York that stop-and-frisk had been implemented by the NYPD in an unconstitutional manner. This decision marked a turning point in the program through the subsequent NYPD mandate that all officers thoroughly justify and document the reason for each stop. Instances of stop-and-frisk declined in the following years due to accusations of racial profiling, as many believed the program disproportionately targeted African-American and Latino individuals. While the percentage of NYPD resources that was devoted to the stop-and-frisk program is not publicly available, the funding and manpower that must have been required to make hundreds of thousands of stops for over a decade begs the question: was the NYPD’s stop-and-frisk program truly effective at reducing crime in New York? Or, was it simply an act of racial discrimination designed to incite fear in the streets? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Research Question(s)\n",
    "\n",
    "We are interested in evaluating crime in New York City over a 10 year period. How has crime changed in New York City from 2009 to 2019? How has the prevalence of certain crimes transformed over this timespan?\n",
    "\n",
    "We are also interested in how implementation of certain policing programs has potentially influenced the crime statistics we find. In particular, we are interested in how the Stop, Question, and Frisk program influenced crime statistics during this period.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## II. Data Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #1: Stop, Question, and Frisk (2011)\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "This dataset was created to document every police-civilian encounter that falls under the NYPD Stop, Question, and Frisk program. The New York City Police Department (NYPD) created the dataset for their records; it is also available for public use. The dataset was funded by the government via taxpayer dollars.\n",
    "\n",
    "**Composition**\n",
    "\n",
    "Each instance (row) of this dataset is a recorded stop of a civilian during 2011. After removing irrelevant columns of data, the dimensions of this dataset was 685,724 x 23. 2011 was the height of the Stop, Question, and Frisk program, which provides an explanation as to why this dataset is so large.\n",
    "\n",
    "Each column represents a different datum regarding the stop recorded for that row. We kept a total of 23 data points regarding a single stop. Those 23 points were about a suspect’s race, age, sex, if an arrest was made, how long they were observed for, how long they were stopped for, the borough the stop was made in, whether a weapon was found on them, if the officer used physical force, and whether a summons was issued to them.\n",
    "\n",
    "This dataset contains all possible instances of people who were stopped during the Stop, Question, and Frisk program. There is the chance that some stops were not recorded in this dataset for reasons outside of our control (ex: an officer did not report it), but if the dataset stays true to its original purpose, it should contain every instance of a stop during the Stop, Question, and Frisk program in 2011.\n",
    "\n",
    "Each instance (row) of this dataset is a recorded stop of a civilian during 2011. Each instance consists of information on the suspect’s race, age, sex, if an arrest was made, how long they were observed for, how long they were stopped for, the borough the stop was made in, whether a weapon was found on them, if the officer used physical force, and whether a summons was issued to them.\n",
    "\n",
    "Each row is assigned an index, starting from count 0. These indices can be used to identify each instance. \n",
    "\n",
    "There are null inputs for some columns but we can generally assume that null means none or no. For example, if no arrest was made, the input for an arrest offense may be null and in this case, null means there is no arrest offense. Relationships between individual instances are not made explicit. One column does record if another person(s) present at the scene of the encounter were also searched, but does not indicate the specific person(s), if any.\n",
    "\n",
    "There are no recommended data splits provided. There are no errors or redundancies in the dataset itself. In the raw dataset, there were definitely values that could be interpreted as redundant, but those were dealt with during the cleaning process. This dataset is self-contained. It does not link to external sources or other datasets.\n",
    "\n",
    "There does not seem to be any confidential data. In addition, for those who are arrested for possession of illegal items, it goes on their record which is a public record. There are no identifying markers of any instances.\n",
    "\n",
    "The dataset may cause some anxiety for those who have lived experience with the Stop, Question, and Frisk program, or those who have negative feelings regarding policing, etc. This dataset does relate to people. This dataset records those who are stopped by police on suspicion of possessing illegal firearms, knives, contraband, etc. It should not be possible to identify individuals from this data after our cleaning process.\n",
    "\n",
    "**Collection Process**\n",
    "\n",
    "The data was collected through the police reports written after a police stop of a civilian was made. This dataset relied on police officers to report and record instances to collect the data. The NYPD was involved in the data collection process. This data was collected in part for the Stop, Question, and Frisk Database that the NYPD maintains. The timeframe of this dataset was the year 2011. No ethical review processes were conducted to our knowledge. Each instance of this dataset represents a person.\n",
    "\n",
    "\n",
    "**Pre-Processing / Cleaning / Labeling**\n",
    "\n",
    "There was no pre-processing done to the data prior to our data cleaning. The steps of our processing / cleaning process are outlined above in Section (a).\n",
    "\n",
    "**Uses**\n",
    "\n",
    "We are unaware if this data has been used for any tasks already. This dataset could definitely be used for an in-depth analysis of the Stop, Question, and Frisk program as a whole, or an analysis of different NYPD-implemented policing programs. I am unaware of any tasks this data should not be used for; if the task is relevant to the Stop, Question, and Frisk Program, this dataset is definitely abundant enough to be used for it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #2: Stop, Question, and Frisk (2019)\n",
    "\n",
    "**Motivation**\n",
    "\n",
    "The dataset was created to record the stops made under New York City Police Department’s Stop, Question, and Frisk program in 2019. The dataset was created by the NYPD. The dataset is funded by taxpayer dollars.\n",
    "\n",
    "**Composition**\n",
    "\n",
    "The instances that comprise the dataset represent every person that was stopped under the Stop, Question, and Frisk program. There are 13,460 instances, meaning 13,460 people were stopped in 2019. The dataset contains all instances of stops in the year 2019. Each instance consists of data on the person’s race, age, sex, if an arrest was made, how long they were observed for, how long they were stopped for, the borough the stop was made in, whether a weapon was found on them, if the officer used physical force, and whether a summons was issued to them. The label associated with each instance is the index of the row that represents that instance.\n",
    "There are null inputs for some columns but we can generally assume that null means none or no. For example, if no arrest was made, the input for an arrest offense may be null and in this case, null means there is no arrest offense. No, they are not made explicit. One of the observations for each instance is if another person was also stopped along with them but the data is either N for no or Y for yes. Therefore, we do not know exactly who the other person that was stopped is. There are no recommended data splits. There are no errors, sources of noise, or redundancies in the dataset. The dataset is self-contained. No, the dataset does not contain data that might be considered confidential. The dataset may cause some anxiety if the person viewing has had a similar experience to being subject to the stop and frisk program. Yes, the dataset contains data on the people who were stopped.\n",
    "The dataset does identify subpopulations by age, sex, and race. There are significantly more males who were stopped in 2019 than females. The most frequently stopped race was Black, with White being the second most stopped race. Asian/Pacific Islander was the least stopped race, excluding the null race category. The most frequently stopped age group was 20-30 year olds with 30-40 year olds as the second most stopped age group. It is not possible to identify individuals based on our cleaned dataset. The dataset contains data on racial origins.\n",
    "\n",
    "**Collection Process**\n",
    "\n",
    "The data associated with each instance was acquired by the officer who initiated the stop. Police reports were used to collect data. The NYPD was involved in the data collection process, compensated by taxpayer dollars. The data was collected from the start to end of 2019. To our knowledge, no ethical review processes were conducted. Yes, the dataset relates to people who were stopped.\n",
    "\n",
    "**Pre-Processing / Cleaning / Labeling**\n",
    "\n",
    "No cleaning, preprocessing, or labeling of the data was done.\n",
    "\n",
    "**Uses**\n",
    "\n",
    "To our knowledge, the dataset has not been used for any tasks already. The dataset could be used for further research into stop and frisk incidents in 2019 or could be compared to other years. There are no tasks for which the dataset should not be used. There is nothing about the composition of the dataset or the way it was collected and preprocessed that might impact future uses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset #3: Criminal Offense Data (2009-2019)\n",
    "\n",
    "**Motivation:**\n",
    "\n",
    "This dataset was created in order to aggregate the annual crime data in New York City, including felony, misdemeanor, and violation offenses from 2009 to 2019. \n",
    "\n",
    "This dataset was composed from four individual datasets created by the New York Police Department (NYPD) for the public. The four original datasets consisted of data regarding the Seven Major Felony Offenses, Non Major Felony Offenses, Misdemeanor Offenses, and Violation Offenses. \n",
    "\n",
    "The creation of the four individual datasets were funded by the government via taxpayer dollars allocated to the NYPD.\n",
    "\n",
    "**Composition:**\n",
    "\n",
    "The instances that comprise the dataset represent the aggregate counts of each type of criminal offense within the categories of Major Felonies, Nonmajor Felonies, Misdemeanors, and Violations reported in NYC by the NYPD by year (2009-2019). There are 374 instances in total in the dataset, indexed by type of offense and year of occurrence. Under each year, there are entries consistent with 34 types of offenses, each of which are considered either a Major Felony, Nonmajor Felony, Misdemeanor, or Violation Offense under New York state and/or Federal Law. For each type of offense, there are 11 entries, one for each year from 2009 to 2019. The dataset is not a sample and contains all possible instances. However, the four datasets from which this one was composed were likely created by aggregating data on each individual criminal offense reported by the NYPD in the relevant time period. Each instance in the dataset consists of an aggregated count for each type of criminal offense reported by the NYPD by year (2009-2019). Each instance is labeled by type of criminal offense, category of offense (Major Felony, Nonmajor Felony, Misdemeanor, or Violation) and year. No information is missing from individual instances. Each instance of data includes the necessary information and context. However, each instance is merely the count per type of criminal offense per year, not the individual instances of crime themselves. The relationship between individual instances is made explicit. The count of each type of criminal offense can be compared across years (2000-2020). Likewise, the count of each type of criminal offense can be compared within each year.\n",
    "\n",
    "There are no recommended data splits. There are no errors, sources of noise, or redundancies in the dataset. This dataset is concise and clean. The dataset is not self-contained. The dataset was created by combining four other datasets, each of which linked to external datasets as sources of information.\n",
    "\n",
    "The dataset does not contain data that might be considered confidential. All the information in the dataset is public NYPD data. The dataset does not contain data that would likely be perceived as offensive, insulting, threatening, or anxiety-inducing if viewed directly. However, given that the data pertains to violent crimes, one could possibly have an emotional response to the data, though it is unlikely. The dataset does not relate to people.\n",
    "\n",
    "**Collection Process**\n",
    "\n",
    "The data associated with each instance is not directly observable, as it was acquired by aggregating data collected from external datasets. The four dataset used to compose this one were produced by the NYPD from their own reporting, so the data was likely validated internally. The data was collected by aggregating individual instances of criminal offenses collected by manual human curation via NYPD reports. The police officers who collected this data did so as part of the crime-reporting operations and public disclosure. These officials of the NYPD were likely compensated in their capacity as a state employee. The data was collected over the course of roughly a decade, 2009-2019.\n",
    "\n",
    "No ethical review processes were conducted as the data collected is the direct byproduct of NYPD operations. The dataset does not relate to people, as each instance of criminal activity is merely one point in an aggregate count and is removed from any individually identifying factors.\n",
    "\n",
    "**Pre-Processing / Cleaning / Labeling**\n",
    "\n",
    "The four datasets used to create the final dataset were likely pre-processed by the NYPD to produce such clean data. Even still, in the process of combining the four datasets, each one had to first be cleaned to eliminate data from years that do not pertain to the timeline of interest within the guiding research question. The four datasets also had to be cleaned to be properly formatted, which included renaming the columns, removing missing values, renaming the offense types, and casting all numbers as ints. Finally, a column was added to indicate the category of offense (Major Felony, Nonmajor Felony, Misdemeanor, or Violation) for reference in the final dataset.\n",
    "\n",
    "The raw data was saved both in the original file formats and as DataFrames (major_felony_raw, nonmajor_felony_raw, misdemeanor_raw, and violation_raw). The dataset was cleaned using Python within a Jupyter Lab Notebook. \n",
    "\n",
    "\n",
    "**Uses**\n",
    "\n",
    "This dataset has not been used for any tasks already. However, the four datasets from which it was composed may have been used for other purposes, though the website in which these datasets were found (ny.gov) does not provide any information regarding any prior use. The dataset could possibly be used for other analyses that pertain to the changes in felony crimes rates in NYC over the last decade. \n",
    "\n",
    "Unfortunately, the provider of the four datasets used to create this one (the NYPD) does not specifically detail their process of collecting and preprocessing the data, so we cannot infer how future users may be impacted by their decisions. In the process of cleaning the final dataset, certain offense types were renamed for ease and consistency. While minimal context was lost, future users would benefit from examining the four datasets from which the final was composed in order to see the offense types as listed by the NYPD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## III. Preregistration Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing Annual NYC Crime Data from 2011 to 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to determine the efficacy of the NYPD's stop-and-frisk program, we must first determine whether there was a relationship between the number of stops and the number of reported crimes in New York during the period of interest (2011-2019). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 1: Linear Regression Analysis of Stop-and Frisk's Efficacy\n",
    "\n",
    "We will perform a linear regression analysis using the number of stops recorded each year as the predictor variable, X, and the number of reported crimes in NYC (in the relevant categories of weapons and contrand) as the criterion variable, Y.\n",
    "\n",
    "This analysis will allow us to establish a relationship between the stop-and-frisk program and crime rates in NYC. With this test we hope to distinguish a decrease in crime due stop-and-frisk from a decrease due to external factors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another analysis we will consider to determine the program's efficacy is a calculation of the percentage of civilians who were stopped that were actually charged with the crime suspected. This metric will provide an understanding of how purposeful and productive the program actually was."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analyzing the Disproportionate Racial Targeting of Stop-and-Frisk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 2: Logistic Regression Analysis of Who is Frisked"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have five possible predictor variables for the logistic regression. Most of them are categorical predictors (race, sex, and borough), and only two are continuous numeric (age and observation duration). We plan to bin the ages and observation duration values and use get_dummies() to map them to indicator variables. The method we will use to bin ages is ages 13-17 inclusive (Teenagers), 18-25 (Young Adults), 26-39 (Adults), 40-65 (Middle-age), 66+ (Seniors). In order to determine the bins for the observation duration values, we must look at the distribution and identify the best partitions for the data.\n",
    "\n",
    "1. Bootstrapping.\n",
    "Need to identify distribution of obs_duration data to determine partitions to get_dummies()\n",
    "Bootstrap, get the 95% confidence interval\n",
    "Then, determine the bins for obs_duration\n",
    "\n",
    "Once all of the variables are in binary/categorical form, we will run a logistic regression using all five predictors and who has been frisked (entered as a True/False value in the table) as the target variable.\n",
    "\n",
    "2. Who is Frisked?\n",
    "Run a Logistic Regression to Predict who is Frisked\n",
    "Use all predictor variables\n",
    "Race - get_dummies() (7 race categories)\n",
    "Age - bin ages by 13-17 inclusive (Teenagers), 18-25 (Young Adults), 26-39 (Adults), 40-65 (Middle-age), 66+ (Seniors)\n",
    "Sex - female = 1, male = 0\n",
    "Borough - get_dummies() (5 borough categories)\n",
    "Obs_duration- bin times based on bootstrap\n",
    "Plot frisked = 1, not frisked = 0\n",
    "Get the prediction accuracy by applying the model to the test data\n",
    "Plot coefficients for each predictor, analyze those coefficients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test 3: Run Chi-Squared Test to Improve Predictors for Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we analyze the accuracy of our initial logistic regression model, we will investigate whether we can improve the model by looking at whether there is a significant dependency between a predictor variable and the target variable. We will see if there is any predictors that should be omitted from the model if they have an insignificant relationship with the target variable.\n",
    "\n",
    "Run Chi-Squared Tests to Improve the Predictors Chosen for the Logistic Regression of who is Frisked:\n",
    "\n",
    "Chi-Squared Tests to Run:\n",
    "Is there a dependence relation between race and who is frisked?\n",
    "Is there a dependence relation between age and who is frisked?\n",
    "Is there a dependence relation between sex and who is frisked?\n",
    "Is there a dependence relation between boro and who is frisked?\n",
    "Is there a dependence relation between observation duration (obs_duration) and who is frisked?\n",
    "\n",
    "The predictors with significant p-values will remain in the logistic regression model.\n",
    "\n",
    "If we do find that there are some predictors that should be omitted, then we will omit them and re-run the logistic regression and see how much the model has improved. Based on which predictors are significant, will inform us what traits/factors have the greatest impact on whether someone is frisked.\n",
    "\n",
    "Depending on the results of the annual NYC crime data and the most influential predictors for determining who is frisked, we will look at those results in conjunction with each other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IV. Data Analyses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## V. Evaluation of Significance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VI. Interpretations and Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VII. Source Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## VIII. Acknowledgements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
